---
title: "Clustering"
format: html
---

Clustering is used when you want to classify your data but you are not sure how. Clustering is a form of **unsupervised** learning.

One type of popular clustering model is **K-means** clustering.

**Assumes**: Spherical clusters of equal variance.

**Strengths**: Fast, simple, works well with large datasets.

**Limitations**: Requires the number of clusters (`k`) to be specified; not great with non-spherical or varying-density clusters.

R package: \[`stats::kmeans()`\], also `cluster` and `factoextra` for visualization.

Another popular type of clustering model is **Hierarchical** clustering.

**Types**: Agglomerative (bottom-up) and divisive (top-down).

**Output**: Dendrogram (tree of clusters).

**Strengths**: Does not require predefined `k`; good for nested structures.

**Limitations**: Computationally expensive for large datasets.

R package: `stats::hclust()`, `dendextend`, `cluster`.

Still another popular type of clustering mode is **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** clustering.

âœ… Why is it popular?
No need to specify the number of clusters in advance (unlike K-means).

Can find arbitrarily shaped clusters, not just spherical ones.

Robust to outliers â€” it can identify noise points as a separate class.

ðŸ§  Core Concepts
Îµ (epsilon): Radius around a point to look for neighboring points.

MinPts: Minimum number of points within Îµ radius to form a dense region.

Core Point: Has at least MinPts within Îµ.

Border Point: Within Îµ of a core point but has fewer than MinPts.

Noise Point: Not a core or border point.

